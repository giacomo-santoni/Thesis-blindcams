{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import drdf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_drdf(fname):\n",
    "  reader = drdf.DRDF()\n",
    "  reader.read(fname)\n",
    "  events = []\n",
    "  for run in reader.runs:\n",
    "    for event in reader.runs[run]:\n",
    "      hits_map = dict()\n",
    "      for cam, img in reader.runs[run][event].items():\n",
    "        amplitude = img.pixels[:, :, 0] \n",
    "        time = img.pixels[:, :, 1]\n",
    "        hits_map[cam] = amplitude\n",
    "      events.append((event, hits_map))\n",
    "  return events\n",
    "\n",
    "#file = load_drdf(\"/Users/giacomosantoni/Desktop/TESI/Progetto_ML/blindcams/response.drdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_drdf_list = [\"/Users/giacomosantoni/Desktop/TESI/Progetto_ML/blindcams/data/initial_data_good/response.drdf\",\"/Users/giacomosantoni/Desktop/TESI/Progetto_ML/blindcams/data/new_data/response_pde25.drdf\",\"/Users/giacomosantoni/Desktop/TESI/Progetto_ML/blindcams/data/new_data2/response.drdf\"]\n",
    "file_root_list = [\"/Users/giacomosantoni/Desktop/TESI/Progetto_ML/blindcams/data/initial_data_good/sensors.root\",\"/Users/giacomosantoni/Desktop/TESI/Progetto_ML/blindcams/data/new_data/sensors_pde25.root\",\"/Users/giacomosantoni/Desktop/TESI/Progetto_ML/blindcams/data/new_data2/sensors.root\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CamList(fname):\n",
    "    cam_list = []\n",
    "    file = load_drdf(fname)\n",
    "    for cam in file[0][1]:\n",
    "        cam_list.append(cam)\n",
    "    return cam_list\n",
    "\n",
    "#cam_list = CamList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creo una matrice 1000 righe x 54 colonne. ogni elemento è una camera 31x31\n",
    "def AllImages(fname): \n",
    "    all_images_list = []\n",
    "    cam_list = CamList(fname)\n",
    "    file = load_drdf(fname)\n",
    "    for i in range(len(file)):\n",
    "        ph_matrix = []\n",
    "        for cam in cam_list:\n",
    "            ph_matrix.append(file[i][1][cam])\n",
    "        all_images_list.append(ph_matrix)\n",
    "    all_images = np.array(all_images_list)\n",
    "    return all_images\n",
    "\n",
    "#all_images = AllImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DimensionsData(fname):\n",
    "    all_images = AllImages(fname)\n",
    "    cam_list = CamList(fname)\n",
    "    nr_events = len(all_images)\n",
    "    nr_pixels = len(all_images[0][0])\n",
    "    nr_cams = len(cam_list)\n",
    "    nr_tot_events = nr_cams*nr_events\n",
    "    nr_pixels_1_ev = nr_pixels*nr_pixels*nr_cams\n",
    "    return nr_events, nr_pixels, nr_cams, nr_tot_events, nr_pixels_1_ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creo una matrice di 1000 righe e 51894 colonne. Così per ogni evento, la riga corrispondente presenta tutti i pixel di tutte le camere\n",
    "def PixelsAllCamsPerEvents(fname):\n",
    "    all_images = AllImages(fname)\n",
    "    nr_events, nr_pixels, nr_cams, nr_tot_events, nr_pixels_1_ev = DimensionsData(fname)\n",
    "    pixels_to_scale = []\n",
    "    for images_all_cams_per_ev in all_images: \n",
    "        pixels_all_cams_per_ev = images_all_cams_per_ev.flatten()\n",
    "        pixels_to_scale.append(pixels_all_cams_per_ev)\n",
    "    pixels_to_scale = np.asarray(pixels_to_scale)\n",
    "    pixels_to_scale_matrix = pixels_to_scale.reshape(nr_events,nr_pixels_1_ev,1)\n",
    "    return pixels_to_scale_matrix\n",
    "\n",
    "#pixels_to_scale_matrix = PixelsAllCamsPerEvents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotCamsImages(fname):\n",
    "    all_images = AllImages(fname)\n",
    "    file = load_drdf(fname)\n",
    "    cam_list = CamList(fname)\n",
    "    for i in range(len(all_images)):\n",
    "        #for cam in cam_list:\n",
    "        for j in range(len(all_images[i])):\n",
    "            plt.imshow(all_images[i][j], interpolation='none')\n",
    "            plt.colorbar()\n",
    "            plt.title(f\"event {file[i][0]} on {cam_list[j]}\")\n",
    "            plt.show()\n",
    "            break\n",
    "        break\n",
    "\n",
    "#PlotCamsImages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCALING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "#applico lo scaling su vettori colonne che sono le camere 31x31 appiattite\n",
    "def ScalingData(fname):\n",
    "    pixels_to_scale_matrix = PixelsAllCamsPerEvents(fname)\n",
    "    nr_events, nr_pixels, nr_cams, nr_tot_events, nr_pixels_1_ev = DimensionsData(fname)\n",
    "    photons_scaled_all_ev = []\n",
    "    for pixels in pixels_to_scale_matrix:\n",
    "        transformer = RobustScaler().fit(pixels)\n",
    "        photons_scaled_in_cam = transformer.transform(pixels)\n",
    "        photons_scaled_all_ev.append(photons_scaled_in_cam)\n",
    "    photons_scaled_all_ev_matrix = np.asarray(photons_scaled_all_ev)\n",
    "    all_images_scaled = photons_scaled_all_ev_matrix.reshape(nr_events,nr_cams,nr_pixels,nr_pixels)\n",
    "    return all_images_scaled\n",
    "\n",
    "#all_images_scaled = ScalingData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ora ho una matrice 1000righex54colonne dove un elemento è una matrice 31x31. Per essere consistente con i dati di root la voglio trasformare in un array di 54000 elementi\n",
    "def Flattening(fname):\n",
    "    all_images_scaled = ScalingData(fname)\n",
    "    all_images_scaled_1d = []\n",
    "    for sublist in all_images_scaled:\n",
    "        all_images_scaled_1d.extend(sublist)\n",
    "    return all_images_scaled_1d\n",
    "\n",
    "#all_images_scaled_1d = np.array(Flattening())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reshaping(fname):\n",
    "    all_images_scaled_1d_reshaped = []\n",
    "    all_images = AllImages(fname)\n",
    "    all_images_scaled_1d = Flattening(fname)\n",
    "    nr_events, nr_pixels, nr_cams, nr_tot_events, nr_pixels_1_ev = DimensionsData(fname)\n",
    "    for data in all_images_scaled_1d:\n",
    "        data_new = data.reshape(nr_pixels,nr_pixels,1)\n",
    "        all_images_scaled_1d_reshaped.append(data_new)\n",
    "    return all_images_scaled_1d_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotCamsImages(fname):\n",
    "    all_images_scaled = ScalingData(fname)\n",
    "    file = load_drdf(fname)\n",
    "    cam_list = CamList(fname)\n",
    "    for i in range(len(all_images_scaled)):\n",
    "        for j in range(len(all_images_scaled[i])):\n",
    "            plt.imshow(all_images_scaled[i][j], interpolation='none')\n",
    "            plt.colorbar()\n",
    "            plt.title(f\"event {file[i][0]} on {cam_list[j]}\")\n",
    "            plt.show()\n",
    "            break\n",
    "        break\n",
    "\n",
    "#PlotCamsImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(fname):\n",
    "    load_drdf(fname)\n",
    "    CamList(fname)\n",
    "    AllImages(fname)\n",
    "    PixelsAllCamsPerEvents(fname)\n",
    "    ScalingData(fname)\n",
    "    Flattening(fname)\n",
    "    return Reshaping(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.28/04\n"
     ]
    }
   ],
   "source": [
    "import ROOT as root\n",
    "\n",
    "def OpenRootFile(rname,fname):\n",
    "    #sensor1.root è il file; ogni camera è un TTree\n",
    "    input_file = root.TFile.Open(rname, \"READ\")\n",
    "    #tree = input_file.Get(\"CAM_NB_X2\")\n",
    "\n",
    "    cam_list = CamList(fname)\n",
    "\n",
    "    nr_photons_list_all_cams_list = []\n",
    "    for cam in cam_list:\n",
    "        nr_photons_list = []\n",
    "        tree = input_file.Get(cam)\n",
    "        entries = tree.GetEntries()\n",
    "        for i in range(entries):\n",
    "            n = tree.GetEntry(i)\n",
    "            inner_photons = tree.innerPhotons\n",
    "            nr_photons_list.append(inner_photons)\n",
    "        nr_photons_list_all_cams_list.append(nr_photons_list)\n",
    "        nr_photons_list_all_cams = np.array(nr_photons_list_all_cams_list)#ho creato una matrice 1000 colonne (nr eventi) x 54 righe (nr camere). I numeri che vediamo sono i numeri di fotoni che arrivano alla camera\n",
    "    return nr_photons_list_all_cams\n",
    "\n",
    "#nr_photons_list_all_cams = np.array(nr_photons_list_all_cams_list)#ho creato una matrice 1000 colonne (nr eventi) x 54 righe (nr camere). I numeri che vediamo sono i numeri di fotoni che arrivano alla camera\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EventListNumber(fname):\n",
    "    file = load_drdf(fname)\n",
    "    ev_list = []\n",
    "    for i in range(len(file)):\n",
    "        ev_list.append(file[i][0])\n",
    "    return ev_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column(matrix, i):\n",
    "    column = [row[i] for row in matrix]\n",
    "    return column\n",
    "\n",
    "def RootDataDictionary(rname,fname):\n",
    "    nr_photons_list_all_cams = OpenRootFile(rname,fname)\n",
    "    ev_list = EventListNumber(fname)\n",
    "    all_photons_in_ev = []\n",
    "    for i in ev_list:\n",
    "        nr_photons_in_ev = column(nr_photons_list_all_cams, i)#lista di fotoni in un determinato evento/sono le colonne delle matrici\n",
    "        all_photons_in_ev.append(nr_photons_in_ev)#faccio una lista di queste liste di fotoni\n",
    "\n",
    "    cam_list = CamList(fname)\n",
    "\n",
    "    final_root_data = []\n",
    "    for i in range(len(all_photons_in_ev)):\n",
    "        nr_photon_in_cam = []\n",
    "        for j in range(len(all_photons_in_ev[i])):\n",
    "            nr_photon_in_cam.append(all_photons_in_ev[i][j])\n",
    "        dict_cam_ev = dict(zip(cam_list, nr_photon_in_cam))\n",
    "        final_root_data.append((ev_list[i], dict_cam_ev))\n",
    "    return final_root_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InnerPhotonsList(rname,fname):\n",
    "    final_root_data = RootDataDictionary(rname, fname)\n",
    "    inner_photons_list = []\n",
    "    for i in range(len(final_root_data)):\n",
    "        for cam in final_root_data[i][1].keys():\n",
    "            inner_photons_list.append(final_root_data[i][1][cam])  \n",
    "    inner_photons_list = np.asarray(inner_photons_list)\n",
    "    return inner_photons_list\n",
    "\n",
    "def CamStatesRootList(rname,fname):\n",
    "    inner_photons_list = InnerPhotonsList(rname,fname)\n",
    "    ev_cam_state_bool = inner_photons_list > 5\n",
    "    ev_cam_state = ev_cam_state_bool.astype(int)\n",
    "    return ev_cam_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RootPreprocessing(rname, fname):\n",
    "    OpenRootFile(rname, fname)\n",
    "    EventListNumber(fname)\n",
    "    RootDataDictionary(rname, fname)\n",
    "    return CamStatesRootList(rname, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_scaled_1d = Preprocessing(file_drdf_list[0])\n",
    "ev_cam_state = RootPreprocessing(file_root_list[0],file_drdf_list[0])\n",
    "#inner_photons_list = InnerPhotonsList(\"/Users/giacomosantoni/Desktop/TESI/Progetto_ML/blindcams/data/initial_data/sensors.root\",\"/Users/giacomosantoni/Desktop/TESI/Progetto_ML/blindcams/data/initial_data/response.drdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#57 eventi e 58 camere, 32x32 pixels\n",
    "data_prep2 = Preprocessing(file_drdf_list[1])\n",
    "ev_cam_state2 = RootPreprocessing(file_root_list[1], file_drdf_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#57 eventi e 60 camere, 32x32 pixels \n",
    "data_prep3 = Preprocessing(file_drdf_list[2])\n",
    "ev_cam_state3 = RootPreprocessing(file_root_list[2],file_drdf_list[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitDataset(rname,fname):\n",
    "    all_images_scaled_1d = Flattening(fname)\n",
    "    inner_photons_list = InnerPhotonsList(rname,fname)\n",
    "    #ev_cam_state = rooprep.CamStatesRootList(rname, fname)\n",
    "    t_ds, val_ds, t_inner_ph, val_inner_ph = train_test_split(all_images_scaled_1d, inner_photons_list, train_size=0.9, random_state=42)\n",
    "    train_ds, test_ds, train_inner_ph, test_inner_ph = train_test_split(t_ds, t_inner_ph, train_size=0.9, random_state=42)\n",
    "\n",
    "    train_ds = np.asarray(train_ds)\n",
    "    val_ds = np.asarray(val_ds)\n",
    "    train_inner_ph = np.asarray(train_inner_ph) \n",
    "    val_inner_ph = np.asarray(val_inner_ph)\n",
    "    test_ds = np.asarray(test_ds) \n",
    "    test_inner_ph = np.asarray(test_inner_ph)\n",
    "\n",
    "    return train_ds, val_ds, test_ds, train_inner_ph, val_inner_ph, test_inner_ph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareDataSingleFile(rname, fname):\n",
    "    train_ds, val_ds, test_ds, train_inner_ph, val_inner_ph, test_inner_ph = SplitDataset(rname,fname)\n",
    "    nr_events, nr_pixels, nr_cams, nr_tot_events, nr_pixels_1_ev = DimensionsData(fname)\n",
    "\n",
    "    train_labels_bool = train_inner_ph > 5\n",
    "    train_labels = train_labels_bool.astype(int)\n",
    "\n",
    "    val_labels_bool = val_inner_ph > 5\n",
    "    val_labels = val_labels_bool.astype(int)\n",
    "\n",
    "    test_labels_bool = test_inner_ph > 5\n",
    "    test_labels = test_labels_bool.astype(int)\n",
    "\n",
    "    train_ds = train_ds.reshape(train_ds.shape[0], nr_pixels,nr_pixels, 1)\n",
    "    val_ds = val_ds.reshape(val_ds.shape[0], nr_pixels, nr_pixels, 1)\n",
    "    test_ds = test_ds.reshape(test_ds.shape[0],nr_pixels,nr_pixels,1)\n",
    "    return train_ds, val_ds, test_ds, train_labels, val_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #dataset1\n",
    "# train_ds1, val_ds1, test_ds1, train_labels1, val_labels1, test_labels1 = PrepareDataSingleFile(file_root_list[0],file_drdf_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #dataset2\n",
    "# train_ds2, val_ds2, test_ds2, train_labels2, val_labels2, test_labels2 = PrepareDataSingleFile(file_root_list[1],file_drdf_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #dataset3\n",
    "# train_ds3, val_ds3, test_ds3, train_labels3, val_labels3, test_labels3 = PrepareDataSingleFile(file_root_list[2],file_drdf_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WholeDataset(rname: list,fname: list):\n",
    "    #dataset1\n",
    "    train_ds1, val_ds1, test_ds1, train_labels1, val_labels1, test_labels1 = PrepareDataSingleFile(rname[0],fname[0])\n",
    "    #dataset2\n",
    "    train_ds2, val_ds2, test_ds2, train_labels2, val_labels2, test_labels2 = PrepareDataSingleFile(rname[1],fname[1])\n",
    "    #dataset3\n",
    "    train_ds3, val_ds3, test_ds3, train_labels3, val_labels3, test_labels3 = PrepareDataSingleFile(rname[2],fname[2])\n",
    "\n",
    "    train_ds = np.concatenate((train_ds1, train_ds2, train_ds3), axis=0)\n",
    "    val_ds = np.concatenate((val_ds1, val_ds2, val_ds3), axis=0)\n",
    "    test_ds = np.concatenate((test_ds1, test_ds2, test_ds3), axis=0)\n",
    "\n",
    "    train_labels = np.concatenate((train_labels1, train_labels2, train_labels3), axis=0)\n",
    "    val_labels = np.concatenate((val_labels1, val_labels2, val_labels3), axis=0)\n",
    "    test_labels = np.concatenate((test_labels1, test_labels2, test_labels3), axis=0)\n",
    "    return train_ds, val_ds, test_ds,train_labels, val_labels,test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindBlindEvents(rname,fname):\n",
    "    ev_cam_state = RootPreprocessing(rname,fname)\n",
    "    data_prep = Preprocessing(fname)\n",
    "    n = 0\n",
    "    nr_blind_events = []\n",
    "    blind_events = []\n",
    "    for i in ev_cam_state:\n",
    "        if i == 1:\n",
    "            nr_blind_events.append(n)\n",
    "        n+=1\n",
    "    for i in nr_blind_events:\n",
    "        blind_events.append(data_prep[i])\n",
    "    return nr_blind_events, blind_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_blind_events1, blind_events1 = FindBlindEvents(file_root_list[0],file_drdf_list[0])\n",
    "nr_blind_events2, blind_events2 = FindBlindEvents(file_root_list[1],file_drdf_list[1])\n",
    "nr_blind_events3, blind_events3 = FindBlindEvents(file_root_list[2],file_drdf_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_events1_sub = []\n",
    "for i in blind_events1:\n",
    "    if np.max(i) > 100:\n",
    "      blind_events1_sub.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Augmentation(rname: list, fname: list):\n",
    "    input_shape = [32,32,32,1]\n",
    "    data_augmentation = keras.Sequential()\n",
    "    data_augmentation.add(layers.RandomFlip(\"horizontal\", input_shape=input_shape[1:]))\n",
    "    data_augmentation.add(layers.RandomRotation(0.2))\n",
    "    data_augmentation.add(layers.RandomTranslation(0.2,0.2))\n",
    "    \n",
    "    #nr_blind_events1, blind_events1 = FindBlindEvents(rname[0], fname[0])\n",
    "    nr_blind_events2, blind_events2 = FindBlindEvents(rname[1], fname[1])\n",
    "    nr_blind_events3, blind_events3 = FindBlindEvents(rname[2], fname[2])\n",
    "    \n",
    "    all_blind_events = np.concatenate((blind_events1_sub,blind_events2,blind_events3), axis=0)\n",
    "\n",
    "    augmented_ds = []\n",
    "    for blind_im in all_blind_events:\n",
    "        for i in range(6):\n",
    "            augmented_image = data_augmentation(blind_im)\n",
    "            augmented_image_sq = np.squeeze(augmented_image, axis=3)\n",
    "            augmented_ds.append(augmented_image_sq)\n",
    "    augmented_ds = np.asarray(augmented_ds)\n",
    "\n",
    "    augmented_labels = len(augmented_ds)*[1]\n",
    "    return augmented_ds, augmented_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DatasetwithAugmentation(rname: list, fname: list):\n",
    "    train_ds, val_ds, test_ds,train_labels, val_labels,test_labels = WholeDataset(rname, fname)\n",
    "    augmented_ds, augmented_labels = Augmentation(rname, fname)\n",
    "    train_ds_aug = np.concatenate((train_ds,augmented_ds),axis=0)\n",
    "    train_labels_aug = np.concatenate((train_labels,augmented_labels),axis=0)\n",
    "    return train_ds_aug, train_labels_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DatasetWeights(rname: list, fname: list):\n",
    "    nr_blind_events1, blind_events1 = FindBlindEvents(rname[0],fname[0])\n",
    "    nr_blind_events2, blind_events2 = FindBlindEvents(rname[1],fname[1])\n",
    "    nr_blind_events3, blind_events3 = FindBlindEvents(rname[2],fname[2])\n",
    "\n",
    "    nr_events1, nr_pixels1, nr_cams1, nr_tot_events1, nr_pixels_1_ev1 = DimensionsData(fname[0])\n",
    "    nr_events2, nr_pixels2, nr_cams2, nr_tot_events2, nr_pixels_1_ev2 = DimensionsData(fname[1])\n",
    "    nr_events3, nr_pixels3, nr_cams3, nr_tot_events3, nr_pixels_1_ev3 = DimensionsData(fname[2])\n",
    "\n",
    "    augmented_ds, augmented_labels = Augmentation(rname, fname)\n",
    "    \n",
    "    nr_blind_ev = len(nr_blind_events1) + len(nr_blind_events2) + len(nr_blind_events3) + len(augmented_ds)\n",
    "    nr_tot_ev = nr_tot_events1 + nr_tot_events2 + nr_tot_events3 + len(augmented_ds)\n",
    "    nr_not_blind_ev = nr_tot_ev - nr_blind_ev\n",
    "\n",
    "    initial_bias = np.log(nr_blind_ev/nr_not_blind_ev)\n",
    "\n",
    "    weights_0 = (1/nr_not_blind_ev)*(nr_tot_ev/2)\n",
    "    weights_1 = (1/nr_blind_ev)*(nr_tot_ev/2)\n",
    "    weights_classes = {0: weights_0, 1: weights_1}\n",
    "    return initial_bias, weights_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Training(rname: list, fname: list): \n",
    "    #initial_bias, weights_classes = DatasetWeights(rname,fname)\n",
    "    input_shape = [32,32,32,1]\n",
    "    #output_bias = keras.initializers.Constant(initial_bias)\n",
    "    model = models.Sequential()\n",
    "    #model.add(data_augmentation)\n",
    "    model.add(layers.Conv2D(8,3,padding='same', activation='ReLU', input_shape=input_shape[1:]))\n",
    "    model.add(layers.Conv2D(16,3,padding='same', activation='ReLU', input_shape=input_shape[1:]))\n",
    "    model.add(layers.Conv2D(16,3,padding='same', activation='ReLU', input_shape=input_shape[1:]))\n",
    "    #model.add(layers.Conv2D(32,3,padding='same', activation='sigmoid', input_shape=input_shape[1:]))\n",
    "    model.add(layers.MaxPooling2D((32,32)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))#, bias_initializer=output_bias))\n",
    "\n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 8)         80        \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 16)        1168      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 1, 1, 16)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3585 (14.00 KB)\n",
      "Trainable params: 3585 (14.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Training(file_root_list, file_drdf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds,train_labels, val_labels,test_labels = WholeDataset(file_root_list, file_drdf_list)\n",
    "train_ds_aug, train_labels_aug = DatasetwithAugmentation(file_root_list,file_drdf_list)\n",
    "initial_bias, weights_classes = DatasetWeights(file_root_list, file_drdf_list)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1656/1656 [==============================] - 21s 13ms/step - loss: 2.0551 - accuracy: 0.9098 - val_loss: 0.4330 - val_accuracy: 0.9249\n",
      "Epoch 2/10\n",
      "1656/1656 [==============================] - 19s 11ms/step - loss: 0.2957 - accuracy: 0.9579 - val_loss: 0.1379 - val_accuracy: 0.9839\n",
      "Epoch 3/10\n",
      "1656/1656 [==============================] - 20s 12ms/step - loss: 0.8323 - accuracy: 0.9064 - val_loss: 0.9595 - val_accuracy: 0.9081\n",
      "Epoch 4/10\n",
      "1656/1656 [==============================] - 21s 13ms/step - loss: 0.9908 - accuracy: 0.9182 - val_loss: 0.6895 - val_accuracy: 0.9455\n",
      "Epoch 5/10\n",
      "1656/1656 [==============================] - 21s 12ms/step - loss: 0.6065 - accuracy: 0.9384 - val_loss: 0.1818 - val_accuracy: 0.9795\n",
      "Epoch 6/10\n",
      "1656/1656 [==============================] - 21s 13ms/step - loss: 0.5063 - accuracy: 0.9558 - val_loss: 0.1627 - val_accuracy: 0.9829\n",
      "Epoch 7/10\n",
      "1656/1656 [==============================] - 20s 12ms/step - loss: 1.1511 - accuracy: 0.9180 - val_loss: 0.7708 - val_accuracy: 0.9364\n",
      "Epoch 8/10\n",
      "1656/1656 [==============================] - 20s 12ms/step - loss: 0.2978 - accuracy: 0.9705 - val_loss: 0.2552 - val_accuracy: 0.9572\n",
      "Epoch 9/10\n",
      "1656/1656 [==============================] - 20s 12ms/step - loss: 0.2191 - accuracy: 0.9711 - val_loss: 0.1810 - val_accuracy: 0.9509\n",
      "Epoch 10/10\n",
      "1656/1656 [==============================] - 20s 12ms/step - loss: 0.2929 - accuracy: 0.9517 - val_loss: 0.1750 - val_accuracy: 0.9689\n"
     ]
    }
   ],
   "source": [
    "#callbacks = [keras.callbacks.ModelCheckpoint(\"/Users/giacomosantoni/Desktop/TESI/Progetto_ML/blindcams/ultima_versione_buoni/tf_model_new/cams_model_new.keras\")]\n",
    "history = model.fit(train_ds_aug, train_labels_aug, validation_data= (val_ds, val_labels), epochs=epochs, batch_size=32, class_weight=weights_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds, val_ds, test_ds,train_labels, val_labels,test_labels = WholeDataset(file_root_list, file_drdf_list)\n",
    "# results = model.evaluate(test_ds,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = model.save(\"/Users/giacomosantoni/Desktop/TESI/Progetto_ML/blindcams/ultima_versione_buoni/tf_model_new/cams_model_aug2.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
